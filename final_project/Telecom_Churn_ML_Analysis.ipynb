{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries needed\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Boosting algorithms\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all 4 datasets to explore individually before combining them\n",
    "\n",
    "contract_df = pd.read_csv('/Users/oliviarohm/Library/Mobile Documents/com~apple~CloudDocs/Desktop/tripleten/my-portfolio/final_project/final_provider/contract.csv')\n",
    "personal_df = pd.read_csv('/Users/oliviarohm/Library/Mobile Documents/com~apple~CloudDocs/Desktop/tripleten/my-portfolio/final_project/final_provider/personal.csv')\n",
    "internet_df = pd.read_csv('/Users/oliviarohm/Library/Mobile Documents/com~apple~CloudDocs/Desktop/tripleten/my-portfolio/final_project/final_provider/internet.csv')\n",
    "phone_df = pd.read_csv('/Users/oliviarohm/Library/Mobile Documents/com~apple~CloudDocs/Desktop/tripleten/my-portfolio/final_project/final_provider/phone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTRACT:\n",
      "Shape: (7043, 8)\n",
      "Columns: ['customerID', 'BeginDate', 'EndDate', 'Type', 'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges']\n",
      "Data types:\n",
      "customerID           object\n",
      "BeginDate            object\n",
      "EndDate              object\n",
      "Type                 object\n",
      "PaperlessBilling     object\n",
      "PaymentMethod        object\n",
      "MonthlyCharges      float64\n",
      "TotalCharges         object\n",
      "dtype: object\n",
      "Missing values:\n",
      "customerID          0\n",
      "BeginDate           0\n",
      "EndDate             0\n",
      "Type                0\n",
      "PaperlessBilling    0\n",
      "PaymentMethod       0\n",
      "MonthlyCharges      0\n",
      "TotalCharges        0\n",
      "dtype: int64\n",
      "Sample data:\n",
      "   customerID   BeginDate              EndDate            Type  \\\n",
      "0  7590-VHVEG  2020-01-01                   No  Month-to-month   \n",
      "1  5575-GNVDE  2017-04-01                   No        One year   \n",
      "2  3668-QPYBK  2019-10-01  2019-12-01 00:00:00  Month-to-month   \n",
      "3  7795-CFOCW  2016-05-01                   No        One year   \n",
      "4  9237-HQITU  2019-09-01  2019-11-01 00:00:00  Month-to-month   \n",
      "\n",
      "  PaperlessBilling              PaymentMethod  MonthlyCharges TotalCharges  \n",
      "0              Yes           Electronic check           29.85        29.85  \n",
      "1               No               Mailed check           56.95       1889.5  \n",
      "2              Yes               Mailed check           53.85       108.15  \n",
      "3               No  Bank transfer (automatic)           42.30      1840.75  \n",
      "4              Yes           Electronic check           70.70       151.65  \n",
      "--------------------------------------------------\n",
      "PERSONAL:\n",
      "Shape: (7043, 5)\n",
      "Columns: ['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents']\n",
      "Data types:\n",
      "customerID       object\n",
      "gender           object\n",
      "SeniorCitizen     int64\n",
      "Partner          object\n",
      "Dependents       object\n",
      "dtype: object\n",
      "Missing values:\n",
      "customerID       0\n",
      "gender           0\n",
      "SeniorCitizen    0\n",
      "Partner          0\n",
      "Dependents       0\n",
      "dtype: int64\n",
      "Sample data:\n",
      "   customerID  gender  SeniorCitizen Partner Dependents\n",
      "0  7590-VHVEG  Female              0     Yes         No\n",
      "1  5575-GNVDE    Male              0      No         No\n",
      "2  3668-QPYBK    Male              0      No         No\n",
      "3  7795-CFOCW    Male              0      No         No\n",
      "4  9237-HQITU  Female              0      No         No\n",
      "--------------------------------------------------\n",
      "INTERNET:\n",
      "Shape: (5517, 8)\n",
      "Columns: ['customerID', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
      "Data types:\n",
      "customerID          object\n",
      "InternetService     object\n",
      "OnlineSecurity      object\n",
      "OnlineBackup        object\n",
      "DeviceProtection    object\n",
      "TechSupport         object\n",
      "StreamingTV         object\n",
      "StreamingMovies     object\n",
      "dtype: object\n",
      "Missing values:\n",
      "customerID          0\n",
      "InternetService     0\n",
      "OnlineSecurity      0\n",
      "OnlineBackup        0\n",
      "DeviceProtection    0\n",
      "TechSupport         0\n",
      "StreamingTV         0\n",
      "StreamingMovies     0\n",
      "dtype: int64\n",
      "Sample data:\n",
      "   customerID InternetService OnlineSecurity OnlineBackup DeviceProtection  \\\n",
      "0  7590-VHVEG             DSL             No          Yes               No   \n",
      "1  5575-GNVDE             DSL            Yes           No              Yes   \n",
      "2  3668-QPYBK             DSL            Yes          Yes               No   \n",
      "3  7795-CFOCW             DSL            Yes           No              Yes   \n",
      "4  9237-HQITU     Fiber optic             No           No               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies  \n",
      "0          No          No              No  \n",
      "1          No          No              No  \n",
      "2          No          No              No  \n",
      "3         Yes          No              No  \n",
      "4          No          No              No  \n",
      "--------------------------------------------------\n",
      "PHONE:\n",
      "Shape: (6361, 2)\n",
      "Columns: ['customerID', 'MultipleLines']\n",
      "Data types:\n",
      "customerID       object\n",
      "MultipleLines    object\n",
      "dtype: object\n",
      "Missing values:\n",
      "customerID       0\n",
      "MultipleLines    0\n",
      "dtype: int64\n",
      "Sample data:\n",
      "   customerID MultipleLines\n",
      "0  5575-GNVDE            No\n",
      "1  3668-QPYBK            No\n",
      "2  9237-HQITU            No\n",
      "3  9305-CDSKC           Yes\n",
      "4  1452-KIOVK           Yes\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Function for comprehensive dataset overview\n",
    "def explore_dataset(df, name):\n",
    "    print(f\"{name.upper()}:\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"Data types:\\n{df.dtypes}\")\n",
    "    print(f\"Missing values:\\n{df.isnull().sum()}\")\n",
    "    print(f\"Sample data:\\n{df.head()}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Apply to each dataset\n",
    "explore_dataset(contract_df, \"contract\")\n",
    "explore_dataset(personal_df, \"personal\")\n",
    "explore_dataset(internet_df, \"internet\")\n",
    "explore_dataset(phone_df, \"phone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overall Observations:**\n",
    "\n",
    "- No missing values in any of the datasets\n",
    "- All datasets contain the same 'customerID' column (dtype: object)\n",
    "- Column naming inconsistencies identified:\n",
    "  - `gender`: lowercase\n",
    "  - `customerID`: camelCase  \n",
    "  - Others: PascalCase (`SeniorCitizen`, `Partner`, etc.)\n",
    "  - **Action**: Standardize to snake_case (lowercase + underscores)\n",
    " \n",
    "**Target Variable 'EndDate':**\n",
    "\n",
    "- Found **only** in **contract_df**\n",
    "    - 'No' = Still active (not churned)\n",
    "    - Date = Left on that date (churned)\n",
    "- **This defines our binary classification target**\n",
    "    - **Next step:** Convert to binary (1=churned, 0=retained)\n",
    "\n",
    "\n",
    "**Different Row Counts:**\n",
    "\n",
    "- Contract: 7,043 customers (100% - baseline)\n",
    "- Personal: 7,043 customers (100% - complete demographic data)  \n",
    "- Internet: 5,517 customers (78.3% - subset with internet service)\n",
    "- Phone: 6,361 customers (90.3% - subset with phone service)\n",
    "    - **Not all customers have all services**\n",
    "    - **Merge strategy: LEFT join on contract_df to retain all customers**\n",
    "\n",
    "**Data Type Issues to Fix:**\n",
    "\n",
    "- **BeginDate & EndDate**: Currently object, need datetime\n",
    "    - Required to calculate customer tenure (key feature)\n",
    "- **TotalCharges**: Currently object, need float64\n",
    "    - Likely contains empty strings or spaces, \"N/A\" or similar text values, special characters or formatting issues \n",
    "    - Must investigate before conversion\n",
    "  \n",
    "**Contract Types:**\n",
    "\n",
    "- Month-to-month\n",
    "- One year\n",
    "- Two year\n",
    "    - **Hypothesis**: Contract length likely correlates with churn rate\n",
    "- **Next**: Verify exact values and explore churn patterns by contract type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Immediate Next Steps:\n",
    "1. Investigate data type issues:\n",
    "   - Examine TotalCharges values\n",
    "   - Check EndDate format variations\n",
    "2. Fix data types (BeginDate, EndDate, TotalCharges)\n",
    "3. Create binary churn target from EndDate\n",
    "4. Standardize column names to snake_case\n",
    "5. Perform LEFT joins to create master dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Investigate Data Type Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalCharges unique value count: 6531\n",
      "\n",
      "Sample of TotalCharges values:\n",
      "TotalCharges\n",
      "         11\n",
      "20.2     11\n",
      "19.75     9\n",
      "20.05     8\n",
      "19.9      8\n",
      "19.65     8\n",
      "45.3      7\n",
      "19.55     7\n",
      "20.15     6\n",
      "20.25     6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Checking for empty/whitespace:\n",
      "TotalCharges\n",
      "         11\n",
      "20.2     11\n",
      "19.75     9\n",
      "20.05     8\n",
      "19.9      8\n",
      "19.65     8\n",
      "45.3      7\n",
      "19.55     7\n",
      "20.15     6\n",
      "20.25     6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Investigate TotalCharges\n",
    "\n",
    "print(\"TotalCharges unique value count:\", contract_df['TotalCharges'].nunique())\n",
    "print(\"\\nSample of TotalCharges values:\")\n",
    "print(contract_df['TotalCharges'].value_counts().head(10))\n",
    "print(\"\\nChecking for empty/whitespace:\")\n",
    "print(contract_df['TotalCharges'].str.strip().value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identified 11 empty string values causing the datatype issue with this column. We need more context as to what those represent in the business context, as it could be new customers, data entry errors, or something else. We will investigate those specific customers before handling them.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers with empty TotalCharges:\n",
      "Empty DataFrame\n",
      "Columns: [customerID, BeginDate, EndDate, TotalCharges]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Look at customers with empty TotalCharges\n",
    "empty_charges = contract_df[contract_df['TotalCharges'] == '']\n",
    "print(\"Customers with empty TotalCharges:\")\n",
    "print(empty_charges[['customerID', 'BeginDate', 'EndDate', 'TotalCharges']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strange that it shows no customers with empty string TotalCharges.** Will investigate further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TotalCharges data type: object\n",
      "\n",
      "First 20 unique values:\n",
      "['29.85' '1889.5' '108.15' '1840.75' '151.65' '820.5' '1949.4' '301.9'\n",
      " '3046.05' '3487.95' '587.45' '326.8' '5681.1' '5036.3' '2686.05'\n",
      " '7895.15' '1022.95' '7382.25' '528.35' '1862.9']\n",
      "Checking for various empty patterns:\n",
      "Empty strings (''): 0\n",
      "Whitespace only: 11\n",
      "NaN values: 0\n",
      "None values: 0\n"
     ]
    }
   ],
   "source": [
    "# Recheck the data type\n",
    "print(f\"\\nTotalCharges data type: {contract_df['TotalCharges'].dtype}\")\n",
    "\n",
    "# Look at some unique values\n",
    "print(f\"\\nFirst 20 unique values:\")\n",
    "print(contract_df['TotalCharges'].unique()[:20])\n",
    "\n",
    "# Check for different types of empty/missing values\n",
    "print(\"Checking for various empty patterns:\")\n",
    "print(f\"Empty strings (''): {(contract_df['TotalCharges'] == '').sum()}\")\n",
    "print(f\"Whitespace only: {(contract_df['TotalCharges'].str.strip() == '').sum()}\")\n",
    "print(f\"NaN values: {contract_df['TotalCharges'].isna().sum()}\")\n",
    "print(f\"None values: {(contract_df['TotalCharges'] == 'None').sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total customers with whitespace TotalCharges: 11\n",
      "\n",
      "Their details:\n",
      "      customerID   BeginDate EndDate  MonthlyCharges TotalCharges      Type\n",
      "488   4472-LVYGI  2020-02-01      No           52.55               Two year\n",
      "753   3115-CZMZD  2020-02-01      No           20.25               Two year\n",
      "936   5709-LVOEQ  2020-02-01      No           80.85               Two year\n",
      "1082  4367-NUYAO  2020-02-01      No           25.75               Two year\n",
      "1340  1371-DWPAZ  2020-02-01      No           56.05               Two year\n",
      "3331  7644-OMVMY  2020-02-01      No           19.85               Two year\n",
      "3826  3213-VVOLG  2020-02-01      No           25.35               Two year\n",
      "4380  2520-SGTTA  2020-02-01      No           20.00               Two year\n",
      "5218  2923-ARZLG  2020-02-01      No           19.70               One year\n",
      "6670  4075-WKNIU  2020-02-01      No           73.35               Two year\n",
      "6754  2775-SEFEE  2020-02-01      No           61.90               Two year\n",
      "\n",
      "BeginDate for these customers:\n",
      "BeginDate\n",
      "2020-02-01    11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "EndDate (churn status):\n",
      "EndDate\n",
      "No    11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Now that we identified that 11 customers contain whitespace-only characters, we can further investigate\n",
    "\n",
    "# Find customers with whitespace TotalCharges\n",
    "whitespace_mask = contract_df['TotalCharges'].str.strip() == ''\n",
    "empty_charges = contract_df[whitespace_mask]\n",
    "\n",
    "print(f\"Total customers with whitespace TotalCharges: {len(empty_charges)}\")\n",
    "print(\"\\nTheir details:\")\n",
    "print(empty_charges[['customerID', 'BeginDate', 'EndDate', 'MonthlyCharges', 'TotalCharges', 'Type']])\n",
    "\n",
    "# Check their tenure\n",
    "print(\"\\nBeginDate for these customers:\")\n",
    "print(empty_charges['BeginDate'].value_counts())\n",
    "\n",
    "# Churn status\n",
    "print(\"\\nEndDate (churn status):\")\n",
    "print(empty_charges['EndDate'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TotalCharges Data Quality Findings:** all 11 customers started on the exact same data (**2020-02-01**) and are all still **active**. All are **long-term contracts**, mostly two years. They all show monthly charges, but whitespace for total charges, which might indicate that their rates have been set, but their first billing cycle hasn't completed yet - which would be explained if the data was collected shortly after (maybe within the same month), of their new contracts. \n",
    "\n",
    "**Next step for handling these values:** we will convert these 11 customers to **0.0** to represent **\"no charges billed yet\"** as it preserves these customers as active, accurately reflects their billing status, and won't skew our analysis with artificial NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalCharges fixed:\n",
      "Data type: float64\n",
      "Zero values (new customers): 11\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Replace whitespace with 0 for new customers (not yet billed)\n",
    "contract_df['TotalCharges'] = contract_df['TotalCharges'].str.strip().replace('', '0')\n",
    "contract_df['TotalCharges'] = contract_df['TotalCharges'].astype(float)\n",
    "\n",
    "# Verify\n",
    "print(\"TotalCharges fixed:\")\n",
    "print(f\"Data type: {contract_df['TotalCharges'].dtype}\")\n",
    "print(f\"Zero values (new customers): {(contract_df['TotalCharges'] == 0).sum()}\")\n",
    "print(f\"Missing values: {contract_df['TotalCharges'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Investigate BeginDate and EndDate Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BeginDate investigation:\n",
      "Unique values: 77\n",
      "\n",
      "Sample values:\n",
      "BeginDate\n",
      "2014-02-01    366\n",
      "2019-10-01    237\n",
      "2019-11-01    237\n",
      "2019-09-01    237\n",
      "2020-01-01    233\n",
      "2019-12-01    220\n",
      "2014-03-01    178\n",
      "2019-07-01    156\n",
      "2019-08-01    146\n",
      "2019-06-01    141\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Date range:\n",
      "First: 2013-10-01\n",
      "Last: 2020-02-01\n",
      "\n",
      "==================================================\n",
      "\n",
      "EndDate investigation:\n",
      "Unique values: 5\n",
      "\n",
      "Value counts:\n",
      "EndDate\n",
      "No                     5174\n",
      "2019-11-01 00:00:00     485\n",
      "2019-12-01 00:00:00     466\n",
      "2020-01-01 00:00:00     460\n",
      "2019-10-01 00:00:00     458\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Date range:\n",
      "First: 2019-10-01 00:00:00\n",
      "Last: No\n",
      "\n",
      "How many 'No' (active customers):\n",
      "5174\n",
      "\n",
      "How many dates (churned customers):\n",
      "1869\n"
     ]
    }
   ],
   "source": [
    "# Check BeginDate values\n",
    "print(\"BeginDate investigation:\")\n",
    "print(f\"Unique values: {contract_df['BeginDate'].nunique()}\")\n",
    "print(f\"\\nSample values:\")\n",
    "print(contract_df['BeginDate'].value_counts().head(10))\n",
    "print(f\"\\nDate range:\")\n",
    "print(f\"First: {contract_df['BeginDate'].min()}\")\n",
    "print(f\"Last: {contract_df['BeginDate'].max()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "#Check EndDate values\n",
    "print(\"\\nEndDate investigation:\")\n",
    "print(f\"Unique values: {contract_df['EndDate'].nunique()}\")\n",
    "print(f\"\\nValue counts:\")\n",
    "print(contract_df['EndDate'].value_counts().head(10))\n",
    "print(f\"\\nDate range:\")\n",
    "print(f\"First: {contract_df['EndDate'].min()}\")\n",
    "print(f\"Last: {contract_df['EndDate'].max()}\")\n",
    "print(f\"\\nHow many 'No' (active customers):\")\n",
    "print((contract_df['EndDate'] == 'No').sum())\n",
    "print(f\"\\nHow many dates (churned customers):\")\n",
    "print((contract_df['EndDate'] != 'No').sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### **Date Column Investigation:**\n",
    "\n",
    "All BeginDate values are in consistent date format. EndDate contains actual dates plus 'No' (active customers with no end date yet), which will cleanly convert to NaT (\"Not a Time\") using `errors='coerce'`.\n",
    "\n",
    "**Key Observations:**\n",
    "\n",
    "**BeginDate:**\n",
    "- Clean date format spanning 2013-10-01 to 2020-02-01 (6+ years)\n",
    "- 77 unique start dates\n",
    "- Confirms dataset captured before February 2020 billing cycle completed\n",
    "\n",
    "**EndDate:**\n",
    "- Only 5 unique values: 4 churn dates + 'No' (active)\n",
    "- All churn concentrated in 4-month window: Oct 2019 - Jan 2020\n",
    "- Much narrower time window than BeginDate\n",
    "\n",
    "**Class Balance:**\n",
    "- Active: 5,174 customers (73.5%)\n",
    "- Churned: 1,869 customers (26.5%)\n",
    "- Moderate imbalance, appropriate for AUC-ROC metric\n",
    "\n",
    "**Implications:**\n",
    "- **DateTime Conversion:** Convert EndDate to datetime format ('No' becomes NaT)\n",
    "- **Target Variable Creation:** Separate binary target column (NaT → 0 retained, dates → 1 churned)\n",
    "- **Data Limitation:** Narrow churn window (4 months) vs wide tenure range (6+ years)\n",
    "  - Question for investigation: What caused concentrated churn Oct 2019-Jan 2020? (Economic factors? Competitor? Policy change?)\n",
    "  - Model will predict churn patterns specific to this period, may not generalize to other market conditions\n",
    "\n",
    "**Next Step:** Convert date columns to datetime format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Date Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date conversions complete:\n",
      "BeginDate dtype: datetime64[ns]\n",
      "EndDate dtype: datetime64[ns]\n",
      "\n",
      "Active customers (EndDate = NaT): 5174\n",
      "Churned customers (EndDate = date): 1869\n",
      "\n",
      "Sample data:\n",
      "   customerID  BeginDate    EndDate\n",
      "0  7590-VHVEG 2020-01-01        NaT\n",
      "1  5575-GNVDE 2017-04-01        NaT\n",
      "2  3668-QPYBK 2019-10-01 2019-12-01\n",
      "3  7795-CFOCW 2016-05-01        NaT\n",
      "4  9237-HQITU 2019-09-01 2019-11-01\n",
      "5  9305-CDSKC 2019-03-01 2019-11-01\n",
      "6  1452-KIOVK 2018-04-01        NaT\n",
      "7  6713-OKOMC 2019-04-01        NaT\n",
      "8  7892-POOKP 2017-07-01 2019-11-01\n",
      "9  6388-TABGU 2014-12-01        NaT\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime\n",
    "contract_df['BeginDate'] = pd.to_datetime(contract_df['BeginDate'])\n",
    "contract_df['EndDate'] = pd.to_datetime(contract_df['EndDate'], errors='coerce')\n",
    "\n",
    "# Verify conversion\n",
    "print(\"Date conversions complete:\")\n",
    "print(f\"BeginDate dtype: {contract_df['BeginDate'].dtype}\")\n",
    "print(f\"EndDate dtype: {contract_df['EndDate'].dtype}\")\n",
    "\n",
    "print(f\"\\nActive customers (EndDate = NaT): {contract_df['EndDate'].isna().sum()}\")\n",
    "print(f\"Churned customers (EndDate = date): {contract_df['EndDate'].notna().sum()}\")\n",
    "\n",
    "print(\"\\nSample data:\")\n",
    "print(contract_df[['customerID', 'BeginDate', 'EndDate']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date Conversion Complete:**\n",
    "- BeginDate & EndDate successfully converted to datetime64[ns]\n",
    "- Active customers ('No') → NaT (5,174)\n",
    "- Churned customers (dates) → datetime (1,869)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Binary Churn Target from EndDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn target created:\n",
      "Churned (1): 1869\n",
      "Retained (0): 5174\n",
      "\n",
      "Churn rate: 26.5%\n",
      "\n",
      "Sample data:\n",
      "   customerID    EndDate  churn\n",
      "0  7590-VHVEG        NaT      0\n",
      "1  5575-GNVDE        NaT      0\n",
      "2  3668-QPYBK 2019-12-01      1\n",
      "3  7795-CFOCW        NaT      0\n",
      "4  9237-HQITU 2019-11-01      1\n",
      "5  9305-CDSKC 2019-11-01      1\n",
      "6  1452-KIOVK        NaT      0\n",
      "7  6713-OKOMC        NaT      0\n",
      "8  7892-POOKP 2019-11-01      1\n",
      "9  6388-TABGU        NaT      0\n"
     ]
    }
   ],
   "source": [
    "# Create binary churn target\n",
    "# 1 = churned (has EndDate), 0 = active (NaT)\n",
    "contract_df['churn'] = contract_df['EndDate'].notna().astype(int)\n",
    "\n",
    "# Verify\n",
    "print(\"Churn target created:\")\n",
    "print(f\"Churned (1): {(contract_df['churn'] == 1).sum()}\")\n",
    "print(f\"Retained (0): {(contract_df['churn'] == 0).sum()}\")\n",
    "print(f\"\\nChurn rate: {contract_df['churn'].mean():.1%}\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample data:\")\n",
    "print(contract_df[['customerID', 'EndDate', 'churn']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Target Variable Created Successfully:\n",
    "\n",
    "- **Column name:** `churn`\n",
    "- **Logic Implemented:** EndDate = NaT → 1 (churned), EndDate = valid dates → 0 (active)\n",
    "- **Distribution:**\n",
    "  - **Churned (1):** 1,869 customers (26.5%)\n",
    "  - **Retained (0):** 5,174 customers (73.5%)\n",
    "- **Modeling note:** Moderate class imbalance is manageable and realistic for churn prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Columns and Perform Left Join on 'contract_df'\n",
    "Will visualize data after this step is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing column name conversions:\n",
      "customerID           -> customer_id\n",
      "BeginDate            -> begin_date\n",
      "EndDate              -> end_date\n",
      "PaperlessBilling     -> paperless_billing\n",
      "PaymentMethod        -> payment_method\n",
      "MonthlyCharges       -> monthly_charges\n",
      "TotalCharges         -> total_charges\n",
      "SeniorCitizen        -> senior_citizen\n",
      "InternetService      -> internet_service\n",
      "OnlineSecurity       -> online_security\n",
      "MultipleLines        -> multiple_lines\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to convert to snake_case\n",
    "def to_snake_case(name):\n",
    "    s1 = re.sub('([a-z])([A-Z])', r'\\1_\\2', name)\n",
    "    return s1.lower()\n",
    "\n",
    "# Function to standardize all columns in a dataframe\n",
    "def standardize_columns(df):\n",
    "    df.columns = [to_snake_case(col) for col in df.columns]\n",
    "    return df\n",
    "\n",
    "# Test function with actual column names from your datasets\n",
    "test_columns = ['customerID', 'BeginDate', 'EndDate', 'PaperlessBilling', \n",
    "                'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'SeniorCitizen',\n",
    "                'InternetService', 'OnlineSecurity', 'MultipleLines']\n",
    "\n",
    "print(\"Testing column name conversions:\")\n",
    "for col in test_columns:\n",
    "    converted = to_snake_case(col)\n",
    "    print(f\"{col:20} -> {converted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Should quickly confirm the customer_id column values are consistent across all four datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTRACT_DF columns: ['customer_id', 'begin_date', 'end_date', 'type', 'paperless_billing', 'payment_method', 'monthly_charges', 'total_charges', 'churn']\n",
      "PERSONAL_DF columns: ['customer_id', 'gender', 'senior_citizen', 'partner', 'dependents']\n",
      "INTERNET_DF columns: ['customer_id', 'internet_service', 'online_security', 'online_backup', 'device_protection', 'tech_support', 'streaming_tv', 'streaming_movies']\n",
      "PHONE_DF columns: ['customer_id', 'multiple_lines']\n",
      "Customer ID overlap check:\n",
      "Contract customers: 7043\n",
      "Personal customers: 7043\n",
      "Internet customers: 5517\n",
      "Phone customers: 6361\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply to all dataframes\n",
    "contract_df = standardize_columns(contract_df)\n",
    "personal_df = standardize_columns(personal_df)\n",
    "internet_df = standardize_columns(internet_df)\n",
    "phone_df = standardize_columns(phone_df)\n",
    "\n",
    "# Verify\n",
    "print(\"CONTRACT_DF columns:\", list(contract_df.columns))\n",
    "print(\"PERSONAL_DF columns:\", list(personal_df.columns))\n",
    "print(\"INTERNET_DF columns:\", list(internet_df.columns))\n",
    "print(\"PHONE_DF columns:\", list(phone_df.columns))\n",
    "\n",
    "# Check if all customer IDs from other datasets exist in contract_df\n",
    "print(\"Customer ID overlap check:\")\n",
    "print(f\"Contract customers: {len(contract_df['customer_id'].unique())}\")\n",
    "print(f\"Personal customers: {len(personal_df['customer_id'].unique())}\")\n",
    "print(f\"Internet customers: {len(internet_df['customer_id'].unique())}\")\n",
    "print(f\"Phone customers: {len(phone_df['customer_id'].unique())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Successfully standardized column names to snake_case & confirmed customer_id overlap as join key across datasets\n",
    "\n",
    "**Questions to consider before merging:**\n",
    "\n",
    "1. How should we handle customers without internet/phone services?\n",
    "   - Include with \"No service\" indicators?\n",
    "   - Or exclude (different churn patterns)?\n",
    "\n",
    "2. Do churn rates differ by service type?\n",
    "   - If yes → service availability is an important feature\n",
    "   - If no → may not matter, but more data is better\n",
    "\n",
    "**Next:** Investigate churn rates by service type before deciding merge strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn analysis by service type:\n",
      "Overall churn rate: 26.5%\n",
      "Internet customers churn rate: 31.8%\n",
      "Phone customers churn rate: 26.7%\n",
      "No internet service churn rate: 7.4%\n",
      "No phone service churn rate: 24.9%\n",
      "Both services churn rate: 32.8%\n"
     ]
    }
   ],
   "source": [
    "# Get full picture of how service types relate to churn patterns\n",
    "\n",
    "# Check churn patterns by service availability\n",
    "print(\"Churn analysis by service type:\")\n",
    "print(f\"Overall churn rate: {contract_df['churn'].mean():.1%}\")\n",
    "\n",
    "# Customers with internet service\n",
    "internet_customers = contract_df['customer_id'].isin(internet_df['customer_id'])\n",
    "print(f\"Internet customers churn rate: {contract_df[internet_customers]['churn'].mean():.1%}\")\n",
    "\n",
    "# Customers with phone service  \n",
    "phone_customers = contract_df['customer_id'].isin(phone_df['customer_id'])\n",
    "print(f\"Phone customers churn rate: {contract_df[phone_customers]['churn'].mean():.1%}\")\n",
    "\n",
    "# Check customers with NO services\n",
    "no_internet = ~internet_customers\n",
    "no_phone = ~phone_customers\n",
    "\n",
    "print(f\"No internet service churn rate: {contract_df[no_internet]['churn'].mean():.1%}\")\n",
    "print(f\"No phone service churn rate: {contract_df[no_phone]['churn'].mean():.1%}\")\n",
    "\n",
    "# Customers with BOTH services\n",
    "both_services = internet_customers & phone_customers\n",
    "print(f\"Both services churn rate: {contract_df[both_services]['churn'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Churn Rate by Service Type:**\n",
    "- No internet: 7.4% (lowest - very loyal)\n",
    "- No phone: 24.9%\n",
    "- Internet customers: 31.8%\n",
    "- Both services: 32.8% (highest)\n",
    "\n",
    "**Conclusion:** Service availability strongly correlates with churn. **Include all customers** - \"No service\" is valuable predictive information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (7043, 21)\n",
      "\n",
      "Missing values after merge:\n",
      "customer_id             0\n",
      "begin_date              0\n",
      "end_date             5174\n",
      "type                    0\n",
      "paperless_billing       0\n",
      "payment_method          0\n",
      "monthly_charges         0\n",
      "total_charges           0\n",
      "churn                   0\n",
      "gender                  0\n",
      "senior_citizen          0\n",
      "partner                 0\n",
      "dependents              0\n",
      "internet_service     1526\n",
      "online_security      1526\n",
      "online_backup        1526\n",
      "device_protection    1526\n",
      "tech_support         1526\n",
      "streaming_tv         1526\n",
      "streaming_movies     1526\n",
      "multiple_lines        682\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# LEFT join all datasets on customer_id\n",
    "df = contract_df.merge(personal_df, on='customer_id', how='left')\n",
    "df = df.merge(internet_df, on='customer_id', how='left')\n",
    "df = df.merge(phone_df, on='customer_id', how='left')\n",
    "\n",
    "# Verify\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "print(f\"\\nMissing values after merge:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shape confirms all customers were preserved (7,043 rows), and all features were combined (21 columns)** \n",
    "\n",
    "**Missing values as expected:**\n",
    "- 1,526 customers without internet service (missing internet-related columns)\n",
    "- 682 customers without phone service (missing multiple_lines column)\n",
    "- 5,174 customers with missing end_date (\"new/NaT customers\" - likely meaning they don't have an end date because they're still **active customers**)\n",
    "\n",
    "**Strategy for missing values:** Because they are **meaningful** to business insights, we will give them meaningful descriptive labels. However, we will **drop end_date column** - as it's already encoded in churn, and keeping it could cause data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after filling:\n",
      "customer_id             0\n",
      "begin_date              0\n",
      "end_date             5174\n",
      "type                    0\n",
      "paperless_billing       0\n",
      "payment_method          0\n",
      "monthly_charges         0\n",
      "total_charges           0\n",
      "churn                   0\n",
      "gender                  0\n",
      "senior_citizen          0\n",
      "partner                 0\n",
      "dependents              0\n",
      "internet_service        0\n",
      "online_security         0\n",
      "online_backup           0\n",
      "device_protection       0\n",
      "tech_support            0\n",
      "streaming_tv            0\n",
      "streaming_movies        0\n",
      "multiple_lines          0\n",
      "dtype: int64\n",
      "\n",
      "Internet service value counts:\n",
      "internet_service\n",
      "Fiber optic            3096\n",
      "DSL                    2421\n",
      "No internet service    1526\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Multiple lines value counts:\n",
      "multiple_lines\n",
      "No                  3390\n",
      "Yes                 2971\n",
      "No phone service     682\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing internet-related columns with 'No internet service'\n",
    "internet_cols = ['internet_service', 'online_security', 'online_backup', \n",
    "                 'device_protection', 'tech_support', 'streaming_tv', 'streaming_movies']\n",
    "df[internet_cols] = df[internet_cols].fillna('No internet service')\n",
    "\n",
    "# Fill missing phone column with 'No phone service'\n",
    "df['multiple_lines'] = df['multiple_lines'].fillna('No phone service')\n",
    "\n",
    "# Verify\n",
    "print(\"Missing values after filling:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nInternet service value counts:\")\n",
    "\n",
    "print(df['internet_service'].value_counts())\n",
    "print(f\"\\nMultiple lines value counts:\")\n",
    "print(df['multiple_lines'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after dropping end_date: (7043, 20)\n",
      "\n",
      "Remaining columns: ['customer_id', 'begin_date', 'type', 'paperless_billing', 'payment_method', 'monthly_charges', 'total_charges', 'churn', 'gender', 'senior_citizen', 'partner', 'dependents', 'internet_service', 'online_security', 'online_backup', 'device_protection', 'tech_support', 'streaming_tv', 'streaming_movies', 'multiple_lines']\n",
      "\n",
      "Missing values:\n",
      "customer_id          0\n",
      "begin_date           0\n",
      "type                 0\n",
      "paperless_billing    0\n",
      "payment_method       0\n",
      "monthly_charges      0\n",
      "total_charges        0\n",
      "churn                0\n",
      "gender               0\n",
      "senior_citizen       0\n",
      "partner              0\n",
      "dependents           0\n",
      "internet_service     0\n",
      "online_security      0\n",
      "online_backup        0\n",
      "device_protection    0\n",
      "tech_support         0\n",
      "streaming_tv         0\n",
      "streaming_movies     0\n",
      "multiple_lines       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop end_date (already encoded as churn target)\n",
    "df = df.drop(columns=['end_date'])\n",
    "\n",
    "# Verify\n",
    "print(f\"Shape after dropping end_date: {df.shape}\")\n",
    "print(f\"\\nRemaining columns: {list(df.columns)}\")\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning Complete:**\n",
    "- Dropped end_date (already encoded as churn target - avoids data leakage)\n",
    "- Final shape: 7,043 × 20\n",
    "- Zero missing values\n",
    "- Customer information (customer_id, begin_date, gender, senior_citizen, etc.)\n",
    "- Service details (internet_service, multiple_lines, streaming services, etc.)\n",
    "- Contract information (type, payment_method, paperless_billing)\n",
    "- Financial data (monthly_charges, total_charges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clarifying Questions\n",
    "\n",
    "**Data & Context:**\n",
    "1. Why is churn data concentrated in a 4-month window (Oct 2019 - Jan 2020)?\n",
    "2. Are there seasonal trends in customer behavior that might explain this timing?\n",
    "3. Are there any known business changes during this period (pricing, competitors, policy)?\n",
    "\n",
    "**Business Goals:**\n",
    "\n",
    "4. What customer characteristics are most associated with churn?\n",
    "5. Which contract types and payment methods lead to higher churn?\n",
    "7. How does service bundling affect churn likelihood?\n",
    "9. Is there a customer tenure \"danger zone\" where churn risk is highest?\n",
    "\n",
    "**Business Impact:**\n",
    "\n",
    "8. What's the cost of acquiring a new customer vs. retaining an existing one?\n",
    "9. What retention strategies are currently in place, and how effective are they?\n",
    "\n",
    "**Operational:**\n",
    "\n",
    "10. What actions can the business take based on model predictions?\n",
    "11. What's the acceptable false positive/negative rate for churn predictions?\n",
    "\n",
    "**Model Deployment:**\n",
    "\n",
    "12. How frequently should the model be retrained?\n",
    "13. What's the timeline for implementing churn prevention actions?\n",
    "\n",
    "**Technical:**\n",
    "\n",
    "14. Given the narrow churn window, will this model generalize to other time periods?\n",
    "15. Are there data privacy constraints on using certain customer features?\n",
    "\n",
    "---\n",
    "\n",
    "## Work Plan\n",
    "\n",
    "**Step 1: Data Preprocessing**\n",
    "Prepare the merged dataset by handling data types, creating the binary churn target, standardizing column names, and ensuring data quality.\n",
    "\n",
    "**Step 2: Feature Engineering**\n",
    "Create new features including:\n",
    "- Customer tenure (months from begin_date)\n",
    "- Service bundling indicators\n",
    "- Charge ratios (monthly vs. total)\n",
    "- Encode categorical variables for modeling\n",
    "\n",
    "**Step 3: Exploratory Data Analysis (EDA)**\n",
    "- Univariate analysis: distributions, outliers\n",
    "- Bivariate analysis: feature vs. churn relationships\n",
    "- Correlation analysis among numeric features\n",
    "- Validate hypotheses (contract type, tenure, charges vs. churn)\n",
    "\n",
    "**Step 4: Model Building**\n",
    "- Split data into train/validation/test sets (60/20/20) to prevent overfitting\n",
    "- Establish baseline model (Logistic Regression)\n",
    "- Train boosting algorithms (handle mixed data types well, provide feature importance, robust to outliers)\n",
    "- Use validation set for hyperparameter tuning and model selection\n",
    "- Evaluate final model on held-out test set\n",
    "\n",
    "**Step 5: Evaluation & Conclusions**\n",
    "- Primary metric: AUC-ROC\n",
    "- Secondary metrics: Accuracy, Precision/Recall\n",
    "- Analyze feature importance for business insights\n",
    "- Document model limitations and recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
